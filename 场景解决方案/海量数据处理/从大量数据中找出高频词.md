>有一个 1GB 大小的文件，文件里每一行是一个词，每个词的大小不超过 16B，内存大小限制是 1MB，要求返回频数最高的 100 个词（Top 100）。



### 一、解答思路

---

**分治 + 堆**

#### 1.1 分块哈希（Hashing）

- 将大文件按哈希值分割成多个小文件（比如 hash % N，分成 N 个小文件）。
  - 每个词根据其哈希值被写入到对应编号的小文件中。
  - 保证相同词落在同一个文件里。
- N 的选择应使得每个小文件的大小不超过内存限制（1MB），例如 N ≈ 1000。

#### 1.2 逐个处理小文件，统计词频

- 对每个小文件读入内存，使用哈希表（`HashMap`）统计词频。
- 将统计结果写入临时文件（格式如：`word count`）。

#### 1.3 使用最小堆合并 Top 100

- 为每个小文件的词频结果建立一个指针（模拟归并排序中的归并）。

- 使用一个 **最小堆（Min-Heap）** 来维护当前 Top 100 中最小的频率词。

- 遍历所有词频结果：

  - 如果当前词频大于堆顶词频，就弹出堆顶，插入当前词。

  - 最终堆中保留的就是频率最高的 100 个词。



### 二、java 实现

---

```java
public class TopKWords {

    private static final int NUM_PARTITIONS = 1000; // 分块数
    private static final int TOP_K = 100;

    public static void main(String[] args) throws IOException {
        String inputFilePath = "input.txt"; // 1GB 文件路径

        // Step 1: 分块写入
        partitionFile(inputFilePath);

        // Step 2: 统计每个分块的词频
        List<String> tempCountFiles = new ArrayList<>();
        for (int i = 0; i < NUM_PARTITIONS; i++) {
            String tempFile = "count_" + i + ".txt";
            countWordsInPartition("partition_" + i + ".txt", tempFile);
            tempCountFiles.add(tempFile);
        }

        // Step 3: 合并结果，找出 Top 100
        PriorityQueue<Map.Entry<String, Integer>> minHeap = new PriorityQueue<>(
                Comparator.comparingInt(Map.Entry::getValue)
        );

        List<BufferedReader> readers = new ArrayList<>();
        for (String file : tempCountFiles) {
            readers.add(Files.newBufferedReader(Paths.get(file)));
        }

        String line;
        for (BufferedReader reader : readers) {
            while ((line = reader.readLine()) != null) {
                String[] parts = line.trim().split("\\s+");
                if (parts.length < 2) continue;
                String word = parts[0];
                int count = Integer.parseInt(parts[1]);

                if (minHeap.size() < TOP_K) {
                    minHeap.offer(new AbstractMap.SimpleEntry<>(word, count));
                } else if (count > minHeap.peek().getValue()) {
                    minHeap.poll();
                    minHeap.offer(new AbstractMap.SimpleEntry<>(word, count));
                }
            }
        }

        // 输出 Top 100
        List<Map.Entry<String, Integer>> result = new ArrayList<>(minHeap);
        result.sort((a, b) -> b.getValue() - a.getValue());
        for (Map.Entry<String, Integer> entry : result) {
            System.out.println(entry.getKey() + ": " + entry.getValue());
        }

        // 清理临时文件（可选）
        for (int i = 0; i < NUM_PARTITIONS; i++) {
            Files.deleteIfExists(Paths.get("partition_" + i + ".txt"));
            Files.deleteIfExists(Paths.get("count_" + i + ".txt"));
        }
    }

    // Step 1: 分块写入
    private static void partitionFile(String inputPath) throws IOException {
        BufferedWriter[] writers = new BufferedWriter[NUM_PARTITIONS];
        for (int i = 0; i < NUM_PARTITIONS; i++) {
            writers[i] = Files.newBufferedWriter(Paths.get("partition_" + i + ".txt"));
        }

        try (BufferedReader reader = Files.newBufferedReader(Paths.get(inputPath))) {
            String line;
            while ((line = reader.readLine()) != null) {
                String word = line.trim();
                int hash = word.hashCode();
                int idx = Math.abs(hash % NUM_PARTITIONS);
                writers[idx].write(word);
                writers[idx].newLine();
            }
        }

        for (BufferedWriter writer : writers) {
            writer.close();
        }
    }

    // Step 2: 统计局部词频
    private static void countWordsInPartition(String inputPath, String outputPath) throws IOException {
        Map<String, Integer> wordCount = new HashMap<>();

        try (BufferedReader reader = Files.newBufferedReader(Paths.get(inputPath));
             BufferedWriter writer = Files.newBufferedWriter(Paths.get(outputPath))) {

            String line;
            while ((line = reader.readLine()) != null) {
                String word = line.trim();
                wordCount.put(word, wordCount.getOrDefault(word, 0) + 1);
            }

            for (Map.Entry<String, Integer> entry : wordCount.entrySet()) {
                writer.write(entry.getKey() + " " + entry.getValue());
                writer.newLine();
            }
        }
    }
}
```