### 一、架构设计：设计一个灵活的RPC框架

---

RPC 就是把拦截到的方法参数，转成可以在网络中传输的二进制，并保证在服务提供方能正确地还原出语义，最终实现像调用本地一样地调用远程的目的。

#### RPC架构设计

网络传输，保证可靠性——>TCP

1. **传输模块**，收发二进制数据，屏蔽网络传输的复杂性。

2. **协议模块**

   - 序列化过程: 用户请求基于方法调用，方法出入参数都是对象数据，对象在网络中传输需要转成二进制；
   - 协议封装: 在方法调用参数的二进制数据后面增加“断句”符号来分隔出不同的请求，在两个“断句”符号中间放的内容就是请求的二进制数据；
   - 压缩功能: 在方法调用参数或者返回值的二进制数据大于某个阈值的情况下，通过压缩框架进行无损压缩，然后在另外一端也用同样的压缩算法进行解压，保证数据可还原；
   - 目的: 保证数据在网络中可以正确传输。

3. **Bootstrap模块**，屏蔽细节，让研发人员感觉不到本地调用和远程调用的区别。可以把一个 RPC 接口定义成一个 Spring Bean，并且这个 Bean 也会统一被 Spring Bean Factory 管理，可以在项目中通过 Spring 依赖注入到方式引用。

4. **集群模块**

   集群能力，就是针对同一个接口有着多个服务提供者，但这多个服务提供者对于调用方来说是透明的，所以在 RPC 里面还需要给调用方找到所有的服务提供方，并需要在 RPC 里面维护好接口跟服务提供者地址的关系，这样调用方在发起请求的时候才能快速地找到对应的接收地址，这就是“**服务发现**”。

   但服务发现只是解决了接口和服务提供方地址映射关系的查找问题，这更多是一种“静态数据”。说它是静态数据是因为，对于 RPC 来说，每次发送请求的时候都是需要用 TCP 连接的，相对服务提供方 IP 地址，**TCP 连接状态是瞬息万变的**，所以 RPC 框架里面要有**连接管理器**去维护 TCP 连接的状态。

   有了集群之后，提供方可能就需要管理好这些服务了，那 RPC 就需要内置一些**服务治理**的功能，比如服务提供方权重的设置、调用授权等一些常规治理手段。而服务调用方在每次调用前，都需要根据服务提供方设置的规则，从集群中选择可用的连接用于发送请求。

四层RPC框架

![在这里插入图片描述](RPC%E5%AE%9E%E6%88%98%E4%B8%8E%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86-%E8%BF%9B%E9%98%B6.assets/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA546L6IOW5rO9,size_20,color_FFFFFF,t_70,g_se,x_16.png)

#### 可扩展的架构-插件化架构

将每个功能点抽象成一个接口，将这个接口作为插件的契约，然后把这个功能的接口与功能的实现分离，并提供接口的默认实现。
在 Java 里面，JDK 有自带的 SPI（Service Provider Interface）服务发现机制，它可以==动态地为某个接口寻找服务实现==。使用 SPI 机制需要在 Classpath 下的 `META-INF/services` 目录里创建一个以服务接口命名的文件，这个文件里的内容就是这个接口的具体实现类。

在实际项目中，其实很少使用到 JDK 自带的 SPI 机制，首先它不能按需加载，==ServiceLoader 加载某个接口实现类的时候，会遍历全部获取，也就是接口的实现类得全部载入并实例化一遍，会造成不必要的浪费==。另外就是扩展如果依赖其它的扩展，那就做不到自动注入和装配，这就很难和其他框架集成，比如扩展里面依赖了一个 Spring Bean，原生的 Java SPI 就不支持。

加上插件功能后, 包含核心功能体系与插件体系的RPC 框架：

![在这里插入图片描述](RPC%E5%AE%9E%E6%88%98%E4%B8%8E%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86-%E8%BF%9B%E9%98%B6.assets/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA546L6IOW5rO9,size_20,color_FFFFFF,t_70,g_se,x_16-20220707103607256.png)

这时，整个架构就变成了一个微内核架构，将每个功能点抽象成一个接口，将这个接口作为插件的契约，然后把这个功能的接口与功能的实现分离并提供接口的默认实现。

这样的架构相比之前的架构，有很多优势:

1. 首先它的可扩展性很好，实现了`开闭原则`，用户可以非常方便地通过插件扩展实现自己的功能，而且不需要修改核心功能的本身；
2. 其次就是保持了核心包的精简，`依赖外部包少`，这样可以有效减少开发人员引入 RPC 导致的包版本冲突问题。



### 二、服务发现：到底是CP还是AP

---

服务发现的作用就是实时感知集群 IP 的变化，实现接口跟服务集群节点 IP 的映射。

在超大规模集群实战中，更多需要考虑的是保证最终一致性AP。总结来说就是: “推拉结合，以拉为准”。

#### 服务发现原理图

![在这里插入图片描述](RPC%E5%AE%9E%E6%88%98%E4%B8%8E%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86-%E8%BF%9B%E9%98%B6.assets/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA546L6IOW5rO9,size_20,color_FFFFFF,t_70,g_se,x_16-20220707134725833.png)

1. 服务注册：在服务提供方启动的时候，将对外暴露的接口注册到注册中心之中，注册中心将这个服务节点的 IP 和接口保存下来。
2. 服务订阅：在服务调用方启动的时候，去注册中心查找并订阅服务提供方的 IP，然后**缓存到本地**，并用于后续的远程调用。

#### 为什么不使用DNS

DNS查询流程

![在这里插入图片描述](RPC%E5%AE%9E%E6%88%98%E4%B8%8E%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86-%E8%BF%9B%E9%98%B6.assets/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA546L6IOW5rO9,size_20,color_FFFFFF,t_70,g_se,x_16-20220708133101579.png)

如果DNS拿来实现服务发现，所有的服务提供者节点都配置在了同一个域名下，调用方的确可以通过 DNS 拿到随机的一个服务提供者的 IP，并与之建立长连接。但是存在问题：

1. 如果这个 IP 端口下线了，服务调用者能否==及时摘除服务节点==呢？不能
2. 如果在之前已经上线了一部分服务节点，这时突然对这个服务进行扩容，那么==新上线的服务节点能否及时接收到流量==呢？-- 不能

为了提升性能和减少DNS服务的压力，**DNS采取了多级缓存机制**，一般配置的缓存时间较长，特别是JVM的默认缓存时永久有效的，所以说**服务调用者不能及时感知到服务节点的变化**。

加一个负载均衡设备, 将域名绑定到这台**负载均衡设备**上，通过 DNS 拿到负载均衡的 IP。这样服务调用的时候，服务调用方就可以直接跟 **VIP** 建立连接，然后由 VIP 机器完成 TCP 转发，如下图所示：

![在这里插入图片描述](RPC%E5%AE%9E%E6%88%98%E4%B8%8E%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86-%E8%BF%9B%E9%98%B6.assets/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA546L6IOW5rO9,size_20,color_FFFFFF,t_70,g_se,x_16-20220708143811291.png)

这个方案确实能解决 DNS 遇到的一些问题，但在 RPC 场景里面也并不是很合适，原因有以下几点：

1. 搭建负载均衡设备或 TCP/IP 四层代理，需求额外成本；
2. 请求流量都经过负载均衡设备，多经过一次网络传输，会额外浪费些性能；
3. 负载均衡添加节点和摘除节点，一般都要手动添加，当大批量扩容和下线时，会有大量的人工操作和生效延迟；
4. 在服务治理的时候，需要更灵活的负载均衡策略，目前的负载均衡设备的算法还满足不了灵活的需求。

结论：DNS 或者 VIP 方案虽然可以充当服务发现的角色，但在 RPC 场景里面直接用还是很难的。

#### 基于Zookeeper的服务发现

搭建一个 ZooKeeper 集群作为注册中心集群，服务注册的时候只需要服务节点向 ZooKeeper 节点写入注册信息即可，利用 ZooKeeper 的 ==Watcher 机制==完成服务订阅与服务下发功能，整体流程如下图：

![在这里插入图片描述](RPC%E5%AE%9E%E6%88%98%E4%B8%8E%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86-%E8%BF%9B%E9%98%B6.assets/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA546L6IOW5rO9,size_20,color_FFFFFF,t_70,g_se,x_16-20220708154017537.png)

1. **服务平台管理**端先在 ZooKeeper 中创建一个服务根路径，可以根据接口名命名（例如：/service/com.demo.xxService），在这个路径再创建**服务提供方目录**与**服务调用方目录**（例如：provider、consumer），分别用来存储服务提供方的节点信息和服务调用方的节点信息。
2. 当服务提供方发起注册时，会在服务提供方目录中创建一个临时节点，节点中存储该服务提供方的注册信息。
3. 当服务调用方发起订阅时，则在服务调用方目录中创建一个临时节点，节点中存储该服务调用方的信息，同时**服务调用方 watch 该服务的服务提供方目录（/service/com.demo.xxService/provider）中所有的服务节点数据**。
4. 当**服务提供方目录下有节点数据发生变更**时，ZooKeeper 就会通知给发起订阅的服务调用方。

>问题现象：
>
>当有超大批量的服务节点在同时发起注册操作，ZooKeeper 集群的 CPU 突然飙升，导致 ZooKeeper 集群不能工作了，而且当时也无法立马将 ZooKeeper 集群重新启动，一直到 ZooKeeper 集群恢复后业务才能继续上线。
>
>当连接到 ZooKeeper 的节点数量特别多，对 ZooKeeper 读写特别频繁，且 ZooKeeper 存储的目录达到一定数量的时候，ZooKeeper 将不再稳定，CPU 持续升高，最终宕机。
>
>而宕机之后，由于各业务的节点还在持续发送读写请求，刚一启动，ZooKeeper 就因无法承受瞬间的读写压力，马上宕机。

#### 基于消息总线的最终一致性的注册中心

zk是顺序一致性。也算最**终一致性**的一种。

ZooKeeper 集群的每个节点的数据每次发生更新操作，都会通知其它 ZooKeeper 节点同时执行更新。它要求**保证每个节点的数据能够实时的完全一致**，这也就直接导致了 ZooKeeper 集群性能上的下降。

> 分布式CAP定理
> 一致性（Consistency）、可用性（Availability）、分区容错性（Partition tolerance）

而 RPC 框架的服务发现，在服务节点刚上线时，服务调用方是可以容忍在一段时间之后（比如几秒钟之后）发现这个新上线的节点的。
毕竟服务节点刚上线之后的几秒内，甚至更长的一段时间内没有接收到请求流量，对整个服务集群是没有什么影响的，所以可以牺牲掉 CP（强制一致性），而==选择 AP（最终一致），来换取整个注册中心集群的性能和稳定性==。

消息总线机制

==注册数据可以全量缓存在每个注册中心内存中，通过消息总线来同步数据==。当有一个注册中心节点接收到服务节点注册时，会产生一个消息推送给消息总线，再通过消息总线通知给其它注册中心节点更新数据并进行服务下发，从而达到注册中心间数据**最终一致性**，具体流程如下图所示：

![在这里插入图片描述](RPC%E5%AE%9E%E6%88%98%E4%B8%8E%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86-%E8%BF%9B%E9%98%B6.assets/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA546L6IOW5rO9,size_20,color_FFFFFF,t_70,g_se,x_16-7591616.png)

- 当服务上线，注册中心节点收到注册请求，服务列表数据会发生变化，会生成一个消息，**推送给消息总线**，每个消息都有整体递增的版本。
- **消息总线会主动推送消息到各个注册中心，同时注册中心也会定时拉取消息**。对于获取到消息的在消息回放模块里面回放，只接受大于本地版本号的消息，小于本地版本号的消息直接丢弃，从而实现最终一致性。
- ==消费者订阅可以从注册中心内存拿到指定接口的全部服务实例，并缓存到消费者的内存里面==。
- 采用**推拉模式**，消费者可以及时地拿到服务实例增量变化情况，并和内存中的缓存数据进行合并。

为了性能，这里采用了**两级缓存，注册中心和消费者的内存缓存**，通过异步推拉模式来确保最终一致性。

Question：服务调方拿到的服务节点不是最新的，所以目标节点存在已经下线或不提供指定接口服务的情况，这个时候有没有问题？

这个问题放到了 RPC 框架里面去处理，在服务调用方发送请求到目标节点后，目标节点会进行**合法性验证**，如果指定接口服务不存在或正在下线，则会拒绝该请求。服务调用方收到拒绝异常后，会安全重试到其它节点。

通过消息总线的方式，就可以完成注册中心集群间数据变更的通知，保证数据的最终一致性，并能及时地触发注册中心的服务下发操作。
服务发现的特性是允许在设计超大规模集群服务发现系统的时候，舍弃强一致性，更多地考虑系统的健壮性。

#### 思考

目前服务提供者上线后会自动注册到注册中心，服务调用方会自动感知到新增的实例，并且流量会很快打到该新增的实例。如果想**把某些服务提供者实例的流量切走**，除了下线实例，有没有想到其它更便捷的办法呢？

官方：
1. 改变服务提供者实例的权重，将权重调整为 0
2. 通过路由的方式也可以
3. 动态分组，业务分组的概念，通过业务分组来实现流量隔离。

如果业务分组是动态的，就可以在管理平台动态地自由调整，是否能实现动态地流量切换？

>服务挂了，在注册中心上还得要手动删除下死亡节点， 如果zk的话，服务没了，就代表会话也没了，临时节点的特性，应该会被通知到呀, 为什么还要手动删除呢? 
>
>**临时节点是需要等到超时时间之后才删除的，不够实时**。
>
>
>
>如果要能切换流量，那么要服务端配置有权重负载均衡策略，这样服务器端可以通过调整权重来安排流量。
>
>
>
>消息总栈类似一个队列，队列表示是递增的数字，注册中心集群的任何一个节点接收到注册请求，都会把服务提供者信息发给消息总栈，消息总栈会像队列以先进先出的原则推送消息给所有注册中心集群节点，集群节点接收到消息后会比较自己内存中的当前版本，保存版本大的，这种方式有很强的实效性，注册中心集群也可以从消息总栈拉取消息，确保数据AP，个人理解这是为了防止消息未接收到导致个别节点数据不准确，因为服务提供者可以向任意一个节点发送注册请求，从而降低了单个注册中心的压力，而注册和注册中心同步是异步的，也解决了集中注册的压力，在Zookeeper中，因为Zookeeper注册集群的强一致性，导致必须所有节点执行完一次同步，才能执行新的同步，这样导致注册处理性能降低，从而高I/O操作宕机。
>
>
>
>问: 当集中注册时，消息总栈下发通知给注册中心集群节点，对于单个节点也会不停的收到更新通知，这里也存在高I/O问题，会不会有宕机？ 
>
>答: event bus可以改造成主从模式保证高可用。
>
>
>
>服务消费者都是从注册中心拉取服务提供者的地址信息，所以要切走某些服务提供者数据，只需要将注册中心这些实例的地址信息删除（其实下线应用实例，实际也是去删除注册中心地址信息），然后注册中心反向通知消费者，消费者受到拉取最新提供者地址信息就没有这些实例了。
>
>问：现有开源注册中心是不是还没有消息总线这种实现方式？消息总线有没有开源实现？
>答：通过服务发现来摘除流量是最常见的手段，还可以上下线状态、权重等方式。现成的MQ也是可以充当消息总线来用。
>
>
>
>问：在AP实现中“两级缓存，注册中心和消费者的内存缓存，通过异步推拉模式来确保最终一致性”能展开讲一下具体实现吗？另外请教下CP可以基于zk实现，AP在业内的实现方式有哪些呢？
>
>主要实现callback，拉的动作在客户端，像Eureka属于AP
>
>
>
>问：消息总线策略是什么，怎么保证消息总线全局版本递增？
>
>答：最简单的就用时间戳。
>
>
>
>zookeeper注册中心实现原理：
>1. 服务平台向zookeeper创建服务目录
>2. 服务提供者向zookeeper创建临时节点
>3. 服务调用者订阅zookeeper，创建临时节点，拉取服务全量数据，watch服务全部节点数据
>4. zookeeper节点发生变化会通知服务调用者切掉服务流量，只需要将注册中心的配置节点下掉就好了，这还是利用了服务发现
>
>
>
>1. 注册中心的核心作用？
>
>   完成服务消费者和服务调用者，两者的路径匹配。
>
>2. 注册中心的核心指标？
>
>   高效、稳定、高可用，使服务消费者及时感知节点的变化
>
>3. 路径匹配需要的信息？
>
>   服务提供者IP、端口、接口、方法+服务分组别名
>
>   服务消费者IP、端口
>
>   路径匹配可以把分组别名利用上，即使提供者实例上线，不过由于设置的别名和服务消费者需要的不一致流量也不会打过去，什么时候打过去可以通过配置中心来自由的控制。分组内也是有多个服务提供者的，这里可以再利用相关的负载均衡策略来具体分发流量。



### 三、健康检测：挂了的节点还疯狂发请求

---

每次发请求前，RPC框架会根据路由和负载均衡算法选择一个具体的IP地址。为了保证请求成功，就需要确保每次选择出来的IP对应的连接是健康的。

终极的解决方案是让调用方实时感知到节点的状态变化。

#### 线上问题实例

线上业务的某个接口可用性并不高，基本上十次调用里总会有几次失败。查看了具体的监控数据之后，发现集群中某台机器出了问题。

![在这里插入图片描述](RPC%E5%AE%9E%E6%88%98%E4%B8%8E%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86-%E8%BF%9B%E9%98%B6.assets/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA546L6IOW5rO9,size_20,color_FFFFFF,t_70,g_se,x_16-20220712234202719.png)

线索：

1. 通过日志发现请求确实会一直打到这台有问题的机器上，因为日志里有很多超时的异常信息。
2. 从监控上看，这台机器还是有一些成功的请求，这**说明当时调用方跟服务之间的网络连接没有断开**。因为如果连接断开之后，RPC 框架会把这个节点标识为“不健康”，不会被选出来用于发业务请求。
3. 深入进去看异常日志，发现**调用方到目标机器的定时心跳会有间歇性失败**。
4. 从目标机器的监控上可以看到该机器的网络指标有异常，出问题时间点 TCP 重传数比正常高 10 倍以上。

结论：

那台问题服务器在某些时间段出现了网络故障，但也还能处理部分请求。但是它还没彻底“死”，还有心跳，这样调用方就觉得它还正常，所以就没有把它及时挪出健康状态列表。

#### 健康检测的逻辑

当服务方下线，正常情况下肯定会收到连接断开的通知事件，在这个事件里面直接加处理逻辑不就可以了？

应用健康状况不仅包含TCP连接状况，还包括应用本身是否存活——>心跳机制。

服务方状态：

1. 健康状态：建立连接成功，并且心跳探活也一直成功；
2. 亚健康状态：建立连接成功，但是心跳请求连续失败；
3. 死亡状态：建立连接失败。

![在这里插入图片描述](RPC%E5%AE%9E%E6%88%98%E4%B8%8E%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86-%E8%BF%9B%E9%98%B6.assets/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA546L6IOW5rO9,size_20,color_FFFFFF,t_70,g_se,x_16-20220713010722461.png)

#### 具体的解决方案

节点：健康状态->亚健康状态，“连续”心跳失败次数必须到达某一个阈值。

如果调低阈值：

1. 调用方跟服务节点之间网络状况瞬息万变，出现网络波动的时候导致误判。
2. 在负载高情况服务端来不及处理心跳请求，由于心跳时间很短，会导致调用方很快触发连续心跳失败而造成断开连接。

问题的本质：

核心是服务节点网络有问题，心跳间歇性失败。

判断节点状态维度：心跳检测 + <<<业务请求>>>

新问题：

- 调用方每个接口的调用频次不一样，有的接口可能1秒内调用上百次，有的接口可能半小时才会调用一次，所以不能简单的把**总失败的次数**当作判断条件。
- 服务的接口响应时间也是不一样的，有的接口可能1ms，有的接口可能是10s，所以也不能把**TPS**用作判断条件。

可用率：某一个时间窗口内接口调用成功次数的百分比（成功次数/总调用次数）当可用率低于某个比例就认为这个节点存在问题，把它挪到亚健康列表，这样既考虑了高低频的调用接口，也兼顾了接口响应时间不同的问题。

#### 总结

正常情况下，大概 30S 会发一次心跳请求。

不能简单地依赖端口的连通性来判断应用是否存活，因为在端口连通正常的情况下，应用也可能僵死了。让每个应用实例提供一个“健康检测”的 URL，检测程序定时通过构造 HTTP 请求访问该 URL，然后根据响应结果来进行存活判断，这样就可以**防止僵死状态的误判**。

> 心跳机制
>
> 如果检测程序所在的机器和目标机器之间的网络可能还会出现故障，导致误判。
>
> 减少误判的几率:
> 那就是把检测程序部署在多个机器里面，分布在不同的机架，甚至不同的机房。
> 因为网络同时故障的概率非常低，所以只要任意一个检测程序实例访问目标机器正常，就可以说明该目标机器正常。



### 四、路由策略：怎么让请求按照设定的规则发到不同的节点上

---

RPC在每次发起请求的时候，都需要从多个服务节点里面选择一个用于发请求的节点。

**节点同质**：这次请求无论发送到集合中的哪个节点上，返回的结果都是一样的。

服务提供方集群：上线应用的时候都不止一台服务器会运行实例 -> 上线涉及到变更 -> 变更可能导致程序异常。为了减少这种风险，一般会选择灰度发布应用实例。但是线上一旦出现问题，影响范围还是挺大的。

那对于RPC框架来说，有什么办法可以减少上线变更导致的风险？

路由在RPC中的应用

#### 如何实现路由策略

方法1：<u>通过服务发现的方式实现流量隔离</u>

在 RPC 里面服务调用方是通过服务发现的方式拿到了所有服务提供方的 IP 地址。当选择要灰度验证功能的时候，让注册中心在推送的时候区别对待，而不是一股脑的把服务提供方的 IP 地址推送到所有调用方。注册中心只会**把刚上线的服务 IP 地址推送到选择指定的调用方**，而其他调用方是不能通过服务发现拿到这个 IP 地址的。

通过服务发现的方式来隔离调用方请求，从逻辑上来看确实可行，但注册中心在 RPC 里面的定位是用来**存储数据并保证数据一致性**的。如果把这种复杂的计算逻辑放到注册中心里面，当集群节点变多之后，就会导致注册中心压力很大，而且大部分情况下一般都是采用开源软件来搭建注册中心，要满足这种需求还需要进行二次开发。所以从实际的角度出发，通过影响服务发现来实现请求隔离并不划算。

方法2：<u>通过负载均衡的方式实现流量隔离</u>
在 RPC 发起真实请求的时候，有一个步骤就是从服务提供方节点集合里面选择一个合适的节点（负载均衡），**在选择节点前加上“筛选逻辑”**，把符合要求的节点筛选出来。筛选逻辑：灰度过程中要验证的规则。

eg：
比如要求新上线的节点只允许某个 IP 可以调用，那注册中心会把这条规则下发到服务调用方。在调用方收到规则后，在选择具体要发请求的节点前，会先通过筛选规则过滤节点集合，按照这个例子的逻辑，最后会过滤出一个节点，这个节点就是刚才新上线的节点。通过这样的改造，RPC 调用流程就变成了这样：

![在这里插入图片描述](RPC%E5%AE%9E%E6%88%98%E4%B8%8E%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86-%E8%BF%9B%E9%98%B6.assets/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA546L6IOW5rO9,size_20,color_FFFFFF,t_70,g_se,x_16-8382626.png)

这个筛选过程在 RPC 里面有一个专业名词，就是“**路由策略**”，而上面例子里面的路由策略是常见的 IP 路由策略，用于限制可以调用服务提供方的 IP。

使用了 IP 路由策略后，整个集群的调用拓扑如下图所示：

![在这里插入图片描述](RPC%E5%AE%9E%E6%88%98%E4%B8%8E%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86-%E8%BF%9B%E9%98%B6.assets/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA546L6IOW5rO9,size_20,color_FFFFFF,t_70,g_se,x_16-20220721135324524.png)

有了 IP 路由之后，上线过程中就可以做到**只让部分调用方请求调用到新上线的实例**，相对传统的灰度发布功能来说，这样做可以把试错成本降到最低。

#### 参数路由

更细粒度的路由方式
在升级改造应用的时候，为了保证调用方能平滑地切调用的新应用逻辑，在升级过程中常用的方式是让新老应用并行运行一段时间，然后通过**切流量百分比**的方式，慢慢增大新应用承接的流量，直到新应用承担了 100% 且运行一段时间后才能去下线老应用。

在流量切换的过程中，为了保证整个流程的完整性，必须保证**某个主题对象的所有请求**都**使用同一种应用来承接**。IP 路由只是限制调用方来源，并不会**根据请求参数请求到预设的服务提供方节点**上去。

给所有的服务提供方节点都打上标签，用来区分新老应用节点。

在服务调用方发生请求的时候，可以很容易地拿到请求参数，可以根据注册中心下发的规则来判断请求参数是过滤掉新应用还是老应用的节点。因为规则对所有的调用方都是一样的，从而保证对应同一个请求参数要么是新应用的节点，要么是老应用的节点。
使用了参数路由策略后，整个集群的调用拓扑如下图所示：







































