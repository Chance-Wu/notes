#### 1. 插入数据

>Elasticsearch 有多种方式插入数据，但最终它们都执行同样的操作，==将 JSON 文档放入 Elasticsearch 索引中==。

>使用简单的PUT请求去执行操作，请求须==指定文档的索引名称==，==唯一的文档ID==，以及==请求体中一个或多个键值对==。
>
>```json
>PUT /customer/_doc/1
>{
>  "name": "John Doe" 
>}
>```
>
>==这个请求（如果不存在）将自动创建一个ID为1的新文档，并存储键值对，并为其建立索引==。
>
>由于这是一个新文档，返回的结果显示新创建的文档版本号为1：
>
>```json
>{
>  "_index" : "customer",
>  "_type" : "_doc",
>  "_id" : "1",
>  "_version" : 1,
>  "result" : "created",
>  "_shards" : {
>    "total" : 2,
>    "successful" : 2,
>    "failed" : 0
>  },
>  "_seq_no" : 0,
>  "_primary_term" : 1
>}
>```
>
>你可以在集群里任意节点去获取文档，你也可以 GET 请求指定 ID 文档：
>
>```json
>GET /customer/_doc/1
>```
>
>返回结果显示找到对应的指定文档，并返回了原始字段信息：
>
>```json
>{
>  "_index" : "customer",
>  "_type" : "_doc",
>  "_id" : "1",
>  "_version" : 1,
>  "_seq_no" : 0,
>  "_primary_term" : 1,
>  "found" : true,
>  "_source" : {
>    "name" : "John Doe"
>  }
>}
>```

#### 2. 批量插入数据

>如果有大量的文档需要插入，你可以使用 `BULK API` 批量插入数据。这要比单独请求提交要快，是因为它最大限度地减少了网络传输次数。
>
>最佳批量插入大小取决于许多因素：
>
>- 文档大小和复杂性
>- 索引
>- 搜索负载
>- 集群的可用资源。
>
>==每次批量处理最好在 1000 ~ 5000 个文档，文档大小最好是在 5M ~ 15M 之间==。
>
>将数据批量导入 Elasticsearch，你就可以开始搜索和分析了。
>下载 `acounts.json` demo 数据。随机生成的 demo 数据展示了以下的用户信息：
>
>```json
>{
>    "account_number": 0,
>    "balance": 16623,
>    "firstname": "Bradshaw",
>    "lastname": "Mckenzie",
>    "age": 29,
>    "gender": "F",
>    "address": "244 Columbus Place",
>    "employer": "Euron",
>    "email": "bradshawmckenzie@euron.com",
>    "city": "Hobucken",
>    "state": "CO"
>}
>```
>
>使用`_bulk`请求将账户数据导入到银行文档中：
>
>```shell
>$ curl -H "Content-Type: application/json" -XPOST "localhost:9200/bank/_bulk?pretty&refresh" --data-binary "@accounts.json"
>$ curl "localhost:9200/_cat/indices?v"
>```
>
>返回结果显示成功导入了1000个文档。

