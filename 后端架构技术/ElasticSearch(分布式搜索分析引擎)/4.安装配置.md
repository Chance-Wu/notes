#### 1. 安装Java

为了运行ES，第一步是安装Java，ES需要Java 7或者更高版本的支持。

#### 2. 安装ES

>安装好Java环境后，下载最新版的ES，解压，安装完毕。

#### 3. ES配置

>Elasticsearch 本身具有适宜的默认值，且需要的配置很少。使用集群更新设置 API 可以更改运行中集群里的大多数设置。
>
>ES有三个配置文件：
>
>- **elasticsearch.yml** 用于配置 Elasticsearch
>- **jvm.options** 用于配置 Elasticsearch JVM 的设置
>- **log4j2.properties** 用户配置 Elasticsearch 日志
>
>配置文件存放在 config 目录下，默认的存放位置取决于安装是从归档发行版（tar.gz 或 zip）还是软件包发行版（Debian 或 RPM 软件包）。
>
>- 对于分布式系统来说，配置文件默认在 `$ES_HOME/config`，可以通过 ES_PATH_CONF 更改配置文件所在的目录位置：
>
>```
>ES_PATH_CONF=/path/to/my/config ./bin/elasticsearch
>```
>
>- 使用 export 方法导出 ES_PATH_CONF 环境变量。
>
>- 如果是软件包安装的系统，默认的配置文件是在 `/etc/elasticsearch`。当然配置文件地址也可以通过修改 ES_PATH_CONF 环境变量而变化。

>**环境变量替换**：配置文件中可以使用 `${...}` 符号引用环境变量，例如：
>
>```yaml
>node.name: ${HOSTNAME}
>network.host: ${ES_NETWORK_HOST}
>```

##### 3.1 JVM参数设置

>修改JVM参数（包括系统属性和JAVA指标）的首选方法是通过修改`jvm.options`，默认的配置文件在`config/jvm.options`（tar或zip方法安装）或者`/etc/elasticsearch/jvm.options`（Linux方法安装）。
>
>该文件包含了以遵循行分隔符为规则的JVM参数：
>
>- 空行将会被忽略
>- 以`#`开头的行被视为注释而被忽略
>- 以`-`开头的行被视为JVM选项 `-Xmx2g`
>- 以数字开头且后跟`:-`的行被视为JVM选项，仅当JVM的版本与数字匹配。 `8:-Xmx2g`
>- 以数字开头的行，后跟 `-:-` 被视为 JVM 选项，仅当 JVM 的版本大于或等于数字时才适用。 `8-:-Xmx2g`
>- 以数字开头，后跟 `-` 在跟数字和`:-` 行被视为 JVM 选项，仅当 JVM 的版本在这两个数字的范围内时才应用该选项。 `8-9:-Xmx2g`
>
>```
>## JVM configuration
>
>################################################################
>## 重要: JVM heap size
>##
>## 应该始终设置最小和最大JVM堆相同的值
>##
>################################################################
>
># Xms 表示堆空间的初始值
># Xmx 表示堆空间的最大值
>
>-Xms1g
>-Xmx1g
>
>################################################################
>## Expert settings
>################################################################
>##
>## 本节以下的所有设置均被视为专家设置。 
>## 除非你了解自己在做什么，否则请不要篡改他们
>##
>################################################################
>
>## GC configuration
>8-13:-XX:+UseConcMarkSweepGC
>8-13:-XX:CMSInitiatingOccupancyFraction=75
>8-13:-XX:+UseCMSInitiatingOccupancyOnly
>
>## G1GC Configuration
># 注意：只有在JDK版本10或更高版本上才能使用G1GC，才支持G1 GC，取消注释后两行并将以下三行中的版本更新为您的JDK版本
># 10-13:-XX:-UseConcMarkSweepGC
># 10-13:-XX:-UseCMSInitiatingOccupancyOnly
>14-:-XX:+UseG1GC
>14-:-XX:G1ReservePercent=25
>14-:-XX:InitiatingHeapOccupancyPercent=30
>
>## JVM 临时目录
>-Djava.io.tmpdir=${ES_TMPDIR}
>
>## heap dumps
>
># 当Java堆的分配失败时，将在JVM的工作目录中创建heap dumps，从而生成heap dumps
>-XX:+HeapDumpOnOutOfMemoryError
>
># 指定heap dump的替代路径； 
># 确保目录存在并且有足够的空间
>-XX:HeapDumpPath=data
>
># 为JVM致命错误日志指定替代路径
>-XX:ErrorFile=logs/hs_err_pid%p.log
>
>## JDK 8 GC 日志
>8:-XX:+PrintGCDetails
>8:-XX:+PrintGCDateStamps
>8:-XX:+PrintTenuringDistribution
>8:-XX:+PrintGCApplicationStoppedTime
>8:-Xloggc:logs/gc.log
>8:-XX:+UseGCLogFileRotation
>8:-XX:NumberOfGCLogFiles=32
>8:-XX:GCLogFileSize=64m
>
># JDK 9+ GC 日志
>9-:-Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m
>```
>

>在上述文件内自定义JVM标签，然后将此文件配置到系统中。设置JAVA虚拟机参数可以通过修改`ES_JAVA_OPTS`环境变量。
>
>```shell
>$ export ES_JAVA_OPTS="$ES_JAVA_OPTS" -Djava.io.tmpdir=/path/to/temp/dir ./bin/elasticsearch
>```
>
>如果是 RPM 或 Debian 包安装时，可以在系统配置中指定 `ES_JAVA_OPTS` 参数值。

##### 3.2 安全设置



##### 3.3 日志配置

>Elasticsearch 使用 Log4j 2 作为日志驱动。可以通过 log4j2.properties 文件配置 Log4j 2 。 Elasticsearch 对外有三个属性：
>
>- `${sys:es.logs.base_path}`  确定了文件的位置
>- `${sys:es.logs.cluster_name}`  被解析为集群名称 （集群名称是日志文件的默认前缀）
>-  `${sys:es.logs.node_name}`   被解析为节点名称（如果节点名称已定义）
>
>例如：如果你的日志文件（path.logs）在 /var/log/elasticsearch 目录下，集群名被命名成 production：
>
>- `${sys:es.logs.base_path}` 将被解析为 `/var/log/elasticsearch`
>- `${sys:es.logs.base_path}${sys:file.separator}${sys:es.logs.cluster_name}.log`被解析成` /var/log/elasticsearch/production.log`。

###### Logging configuration

>######## Server JSON ############################
>1.appender.rolling.type = RollingFile 
>appender.rolling.name = rolling
>2.appender.rolling.fileName = ${sys:es.logs.base_path}${sys:file.separator}${sys:es.logs.cluster_name}_server.json 
>3.appender.rolling.layout.type = ESJsonLayout 
>4.appender.rolling.layout.type_name = server 
>5.appender.rolling.filePattern = ${sys:es.logs.base_path}${sys:file.separator}${sys:es.logs.cluster_name}-%d{yyyy-MM-dd}-%i.json.gz 
>appender.rolling.policies.type = Policies
>6.appender.rolling.policies.time.type = TimeBasedTriggeringPolicy 
>7.appender.rolling.policies.time.interval = 1 
>8.appender.rolling.policies.time.modulate = true 
>9.appender.rolling.policies.size.type = SizeBasedTriggeringPolicy 
>10.appender.rolling.policies.size.size = 256MB 
>appender.rolling.strategy.type = DefaultRolloverStrategy
>appender.rolling.strategy.fileIndex = nomax
>11.appender.rolling.strategy.action.type = Delete 
>appender.rolling.strategy.action.basepath = ${sys:es.logs.base_path}
>12.appender.rolling.strategy.action.condition.type = IfFileName 
>13.appender.rolling.strategy.action.condition.glob = ${sys:es.logs.cluster_name}-* 
>14.appender.rolling.strategy.action.condition.nested_condition.type = IfAccumulatedFileSize 
>15.appender.rolling.strategy.action.condition.nested_condition.exceeds = 2GB 
>################################################
>
>1. 配置`RollingFile` appender
>2. 日志位置： `/var/log/elasticsearch/production.json`
>3. 使用 JSON 布局。
>4. `type_name` 是一个标识， 用于填充 `ESJsonLayout` 中的 `type` 字段。解析日志时，可以更加轻松地区别不同类型的日志。
>5. 日志回滚到：`/var/log/elasticsearch/production-yyyy-MM-dd-i.json`；每次回滚日志都将会被压缩，日志名称 i 参数每次递增。
>6. 使用基于时间回滚策略
>7. 每天回滚日志
>8. 在日边界对齐（凌晨）回滚 (而不是每 24 小时回滚一次)
>9. 使用基于大小的回滚策略
>10. 日志大于 256M 进行回滚
>11. 使用删除操作回滚日志
>12. 仅删除匹配到的日志
>13. 只删除主日志
>14. 仅日志大于多少才删除
>15. 当日志大于 2G 时压缩

>######## Server -  old style pattern ###########
>appender.rolling_old.type = RollingFile
>appender.rolling_old.name = rolling_old
>appender.rolling_old.fileName = ${sys:es.logs.base_path}${sys:file.separator}${sys:es.logs.cluster_name}_server.log 
>appender.rolling_old.layout.type = PatternLayout
>appender.rolling_old.layout.pattern = [%d{ISO8601}][%-5p][%-25c{1.}] [%node_name]%marker %m%n
>appender.rolling_old.filePattern = ${sys:es.logs.base_path}${sys:file.separator}${sys:es.logs.cluster_name}-%d{yyyy-MM-dd}-%i.old_log.gz
>
>1. `old style` 配置参数为追加模式，这些日志将被保存在 `*.log` 文件中，如果日志被归档了，则将保存在 `* .log.gz` 文件中。请注意，如果配置被弃用，之后需删除。

>你可以用 appender.rolling.filePattern 中的 .zip 替代.gz 以压缩回滚日志。如果删除 .gz 扩展名，则日志在回滚时将不会被压缩。
>
>如果你想在指定时间段内保存日志文件，则可以将过渡策略和删除操作一起使用。
>
>appender.rolling.strategy.type = DefaultRolloverStrategy 
>appender.rolling.strategy.action.type = Delete 
>appender.rolling.strategy.action.basepath = ${sys:es.logs.base_path} 
>appender.rolling.strategy.action.condition.type = IfFileName 
>appender.rolling.strategy.action.condition.glob = ${sys:es.logs.cluster_name}-* 
>appender.rolling.strategy.action.condition.nested_condition.type = IfLastModified 
>appender.rolling.strategy.action.condition.nested_condition.age = 7D 
>
>1. 配置 DefaultRolloverStrategy
>2. 配置回滚过程中类型为删除
>3. Elasticsearch 日志路径地址
>4. 回滚时的条件
>5. 从基本路径中删除与全局 $ {sys：es.logs.cluster_name}-* 相匹配的文件；这是日志文件滚动到的位置；仅删除滚动的 Elasticsearch 日志，而不删除过时和慢速日志，这是必需的
>6. 嵌套条件适用于与 glob 匹配的文件
>7. 保留日志 7 天
>
>可以加载多个配置文件 (在这种情况下，这些配置文件将被合并)，只要它们的名为 log4j2.properties 并将 Elasticsearch 配置目录作为父类；这对于公开其他记录器的插件很有用。日志驱动部分包含 java 包及其相应的日志级别。

>**注意**:Log4j’s 配置解析时会被任何多余的空格所混淆，如果你在此页面上的复制并粘贴任何 Log4j 设置，或者手输任何 Log4j 配置，请务必修建任何行前和行尾的空白。

###### 配置日志等级

>四种方式：
>
>1. 修改命令行：`-E <name of logging hierarchy>=<level>` (e.g., `-E logger.org.elasticsearch.transport=trace`)。当你在单节点上临时调试问题（例如，问题重现或者开发时），这是最合适的方式。
>2. 修改 `elasticsearch.yml` 文件: `<name of logging hierarchy>: <level>` (e.g., `logger.org.elasticsearch.transport: trace`). 当你临时调试的时候，但没有通过命令行（或者通过服务）去启动 Elasticsearch ，或者你想永久的改变日志记录级别，这是最合适的方法。
>3. 集群设置修改:
>
>```
>PUT /_cluster/settings
>{
>  "transient": {
>      "<name of logging hierarchy>": "<level>"
>  }
>}
>```
>
>例如：
>
>```
>PUT /_cluster/settings
>{
>  "transient": {
>      "logger.org.elasticsearch.transport": "trace"
>  }
>}
>```
>
>当需要动态调整集群的日志记录级别，这是最合适的。
>
>4. 通过修改`log4j2.proeprties`配置文件
>
>```properties
>logger.<unique_identifier>.name =  <name of logging hierarchy>
>logger.<unique_identifier>.level =  <level>
>```
>
>当你需要对日志进行细粒度控制时（例如需要将日志写到到其他文件中去，或者以不同的方式管理日志，这是一种罕见的用法），这是最适合的方法。

###### 弃用日志

>除了常规日志记录外，Elasticsearch 允许你启动弃用日志操作。例如，这让你提早下定决心确认是否迁移某些功能。默认情况下，在 WARN 级别启动弃用日志，该级别上所有日志都将被弃用。
>
>`logger.deprecation.level = warn`
>
>这将在日志目录中创建每日回滚弃用日志文件，定期检查此文件，特别是当你打算升级到某一个新主版本时。
>
>默认的日志记录配置，将弃用日志的回滚策略设为：1G 之后回滚压缩，并最多保留五个日志文件（四个回滚日志和 1 个活动日志）
>
>你也可通过在 config/log4j2.properties 文件中禁用它，弃用日志配置设置为 error，如图所示：
>
>```properties
>logger.deprecation.name = org.elasticsearch.deprecation
>logger.deprecation.level = error
>```

###### JSON 日志格式

>为了简化对 Elasticsearch 日志的解析，日志以 JSON 格式打印。这是通过
>Log4J 的布局属性 `appender.rolling.layout.type = ESJsonLayout` 进行配置。需要设置 `type_name`，该属性用于解析时区分日志流。

##### 3.4 elasticsearch.yml 配置

>- 路径设置
>- 集群名称
>- 节点名称
>- 主机网络
>- 发现设置
>- 堆大小
>- 堆存储路径
>- GC日志
>- 临时文件

###### 3.4.1 数据、日志路径设置



###### 3.4.2 集群名称



###### 3.4.3 节点名称



###### 3.4.4 主机网络



###### 3.4.5 重要的发现和集群初始化设置



###### 3.4.6 堆大小设置



###### 3.4.7 JVM heap dump 文件路径



###### 3.4.8 GC 日志



###### 3.4.9 临时文件



###### 3.4.10 JVM 致命错误日志



#### 4. 启动

>```shell
>$ ./bin/elsaticsearch
>```
>
>现在，已经创建并运行了一个单节点 Elasticsearch 集群。

>启动另外两个Elasticsearch实例，以便你可以看到经典的多节点集群的行为。需要为每个节点指定唯一的数据和日志路径。
>
>```shell
>./elasticsearch -E path.data=data2 -E path.logs=log2
>./elasticsearch -E path.data=data3 -E path.logs=log3
>```
>
>为其他节点分配了唯一的ID。在本地运行所有三个节点，它们会自动与第一个节点一起加入集群。
>
>1. 使用 `cat health API` 去验证三个节点的集群是否运行， `cat APIs` 比原始 JSON 返回的格式更容易阅读相关集群和索引的信息。
>
>2. 打开Kibana通过开发控制台提交请求。
>
>通过向 Elasticsearch REST API 提交 HTTP 请求来直接与集群交互。
>
>```
>GET /_cat/health?v
>例如：
>http://localhost:9200/_cat/health?v
>```
>
><img src="https://tva1.sinaimg.cn/large/0081Kckwgy1glireljf3lj31sc02mmx8.jpg" style="zoom:60%">
>
>返回的结果显示：Elasticsearch集群的`status`是`green`，`node.total`是`3`。
>
>如果是只运行一个 Elasticsearch 实例，则集群状态将保持黄色。单节点群集具有完整的功能，但是无法将数据复制到另一个节点以提供弹性。副本分片必须可用，群集状态才会显示绿色。如果群集状态为红色，则表示某些数据不可用。
>

