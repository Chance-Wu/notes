### 一、connection

---

connection 就是**对 tcp 连接的封装**，其中包括连接的 socket，读事件，写事件。利用 nginx 封装的 connection，我们可以很方便的使用 Nginx 来处理与连接相关的事情，比如，**建立连接，发送与接受数据**等。而 Nginx 中的 http 请求的处理就是建立在 connection之上的，所以 **Nginx 不仅可以作为一个web服务器，也可以作为邮件服务器**。当然，利用 Nginx 提供的 connection，我们可以与任何后端服务打交道。

#### 1.1 处理一个连接的流程

结合一个tcp连接的生命周期，我们看看nginx是如何处理一个连接的。

1. 首先，nginx在启动时，会解析配置文件，得到需要监听的端口与ip地址；
2. 然后在nginx的master进程里面，先初始化好这个监控的socket；
   1. 创建 socket
   2. 设置 addrreuse 等选项
   3. 绑定到指定的 ip 地址端口
   4. 再 listen
3. 然后再 fork 出多个子进程出来，然后子进程会竞争 accept 新的连接；
4. 此时，客户端就可以向 nginx 发起连接了。当客户端与服务端通过三次握手建立好一个连接后，nginx 的某一个子进程会 accept 成功，得到这个建立好的连接的 socket，然后创建 nginx 对连接的封装，即 `ngx_connection_t` 结构体；
5. 接着，设置读写事件处理函数并添加读写事件来与客户端进行数据的交换。最后，nginx 或客户端来主动关掉连接，到此，一个连接就结束了。

#### 1.2 nginx作为客户端请求其它 server 的数据

如upstream模块。

此时，与其它 server 创建的连接，也封装在 ngx_connection_t 中。作为客户端，nginx 先获取一个 ngx_connection_t 结构体，然后创建 socket，并设置 socket 的属性（ 比如非阻塞）。然后再通过添加读写事件，调用 connect/read/write 来调用连接，最后关掉连接，并释放 ngx_connection_t。

#### 1.3 最大连接数上限

在 nginx 中，每个进程会有一个连接数的最大上限，这个上限与系统对 fd 的限制不一样。在操作系统中，**通过 `ulimit -n`，我们可以得到一个进程所能够打开的 fd 的最大数，即 nofile，因为每个 socket 连接会占用掉一个 fd，所以这也会限制我们进程的最大连接数，当然也会直接影响到我们程序所能支持的最大并发数**，当 fd 用完后，再创建 socket 时，就会失败。Nginx 通过设置 worker_connectons 来设置每个进程支持的最大连接数。如果该值大于 nofile，那么实际的最大连接数是 nofile，nginx 会有警告。nginx 在实现时，是通过一个连接池来管理的，**每个 worker 进程都有一个独立的连接池，连接池的大小是 worker_connections**。这里的连接池里面保存的其实不是真实的连接，它只是一个 worker_connections 大小的一个 ngx_connection_t 结构的数组。并且，Nginx 会通过一个链表 free_connections 来保存所有的空闲 ngx_connection_t，每次获取一个连接时，就从空闲连接链表中获取一个，用完后，再放回空闲连接链表里面。

>一个 nginx 能建立的最大连接数，应该是`worker_connections * worker_processes`。当然，这里说的是最大连接数，对于 HTTP 请求本地资源来说，能够支持的最大并发数量是`worker_connections * worker_processes`，而如果是 HTTP 作为反向代理来说，最大并发数量应该是`worker_connections * worker_processes/2`。因为作为反向代理服务器，每个并发会建立与客户端的连接和与后端服务的连接，会占用两个连接。

#### 1.4 如何

一个客户端连接过来后，多个空闲的进程，会竞争这个连接，这种竞争会导致不公平，如果某个进程得到 accept 的机会比较多，它的空闲连接很快就用完了，如果不提前做一些控制，当 accept 到一个新的 tcp 连接后，因为无法得到空闲连接，而且无法将此连接转交给其它进程，最终会导致此 tcp 连接得不到处理，就中止掉了。很显然，这是不公平的，有的进程有空余连接，却没有处理机会，有的进程因为没有空余连接，却人为地丢弃连接。那么，如何解决这个问题呢？

首先，nginx 的处理得先打开 accept_mutex 选项，此时，只有获得了 accept_mutex 的进程才会去添加accept事件，也就是说，Nginx会控制进程是否添加 accept 事件。Nginx 使用一个叫 ngx_accept_disabled 的变量来控制是否去竞争 accept_mutex 锁。在第一段代码中，计算 ngx_accept_disabled 的值，这个值是 Nginx 单进程的所有连接总数的八分之一，减去剩下的空闲连接数量，得到的这个 ngx_accept_disabled 有一个规律，当剩余连接数小于总连接数的八分之一时，其值才大于 0，而且剩余的连接数越小，这个值越大。再看第二段代码，当 ngx_accept_disabled 大于 0 时，不会去尝试获取 accept_mutex 锁，并且将 ngx_accept_disabled 减 1，于是，每次执行到此处时，都会去减 1，直到小于 0。不去获取 accept_mutex 锁，就是等于让出获取连接的机会，很显然可以看出，当空余连接越少时，ngx_accept_disable 越大，于是让出的机会就越多，这样其它进程获取锁的机会也就越大。不去 accept，自己的连接就控制下来了，其它进程的连接池就会得到利用，这样，Nginx 就控制了多进程间连接的平衡了。



































